---
title: "Assignment 2 - Language Development in ASD - Part 1 - Explaining development"
author: "The Eyes of Kasparov "
date: "2020-09-15"
output: html_document
---
    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(include = TRUE)
```

# Assignment 2

In this assignment you will have to discuss a few important questions (given the data you have). More details below. The assignment submitted to the teachers consists of:
- a report answering and discussing the questions (so we can assess your conceptual understanding and ability to explain and critically reflect)
- a link to a git repository with all the code (so we can assess your code)

Part 1 - Basic description of language development
- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced
- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). 
- Describe how parental use of language (in terms of MLU) changes over time. What do you think is going on?
- Include individual differences in your model of language development (in children). Identify the best model.

Part 2 - Model comparison
- Discuss the differences in performance of your model in training and testing data
- Which individual differences should be included in a model that maximizes your ability to explain/predict new data?
- Predict a new kid's performance (Bernie) and discuss it against expected performance of the two groups

Part 3 - Simulations to plan a new study
- Report and discuss a power analyses identifying how many new kids you would need to replicate the results

The following involves only Part 1.

## Learning objectives

- Summarize and report data and models
- Critically apply mixed effects (or multilevel) models
- Explore the issues involved in feature selection


# Quick recap
Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has not been empirically traced in detail:
i) relying on actual naturalistic language production,  ii) over extended periods of time.

We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class. 

NB. A few children have been excluded from your datasets. We will be using them next week to evaluate how good your models are in assessing the linguistic development in new participants.

This RMarkdown file includes 
1) questions (see above). Questions have to be answered/discussed in a separate document that you have to directly submit on Blackboard.
2) A break down of the questions into a guided template full of hints for writing the code to solve the exercises. Fill in the code and the paragraphs as required. Then report your results in the doc for the teachers.

REMEMBER that you will have to have a github repository for the code and submit the answers to Blackboard without code (but a link to your github/gitlab repository). This way we can check your code, but you are also forced to figure out how to report your analyses :-)

Before we get going, here is a reminder of the issues you will have to discuss in your report:

1- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced
2- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). 
3- Describe how parental use of language (in terms of MLU) changes over time. What do you think is going on?
4- Include individual differences in your model of language development (in children). Identify the best model.

# Let's go

### Loading the relevant libraries

Load necessary libraries : what will you need?
- e.g. something to deal with the data
- e.g. mixed effects models
- e.g. something to plot with

```{r Load Libraries, include = TRUE}
library(tidyverse)
library(lmerTest)
library(pastecs)
```

### Define your working directory and load the data
If you created a project for this class and opened this Rmd file from within that project, your working directory is your project directory.

If you opened this Rmd file outside of a project, you will need some code to find the data:
- Create a new variable called locpath (localpath)
- Set it to be equal to your working directory
- Move to that directory (setwd(locpath))
- Load the data you saved last time (use read_csv(fileName))

```{r Load Data, include = TRUE}
df <- read_csv("final_data.csv")

df <- df %>% 
  mutate(Gender = if_else(Gender == "M", "F", "M"), 
         # Sorting ethnicity into white and other
         Ethnicity = if_else(str_detect(tolower(Ethnicity), "white"), "White", "Other")) %>% 
  # For comparing models
  drop_na()

```

### Characterize the participants (Exercise 1)

Identify relevant variables: participants demographic characteristics, diagnosis, ADOS, Verbal IQ, Non Verbal IQ, Socialization, Visit, Number of words used, Number of unique words used, mean length of utterance in both child and parents.

Make sure the variables are in the right format.

Describe the characteristics of the two groups of participants and whether the two groups are well matched.

```{r descriptive stats, include = TRUE}

# Plotting intelligence distributions # 
non_verbal_plot <- ggplot(df, aes(y = MullenRaw, x = Diagnosis)) + 
  geom_boxplot() + 
  labs(title = "Non-verbal intelligence comparison", 
       y = "Non-verbal IQ-scoreScore") + 
  theme_minimal()

verbal_intelligence_plot <- ggplot(df, aes(y = ExpressiveLangRaw, x = Diagnosis)) + 
  geom_boxplot() + 
  labs(title = "Verbal intelligence comparison", 
       y = "Verbal IQ-score") + 
  theme_minimal()

Socialization_plot <- ggplot(df, aes(y = Socialization, x = Diagnosis)) + 
  geom_boxplot() + 
  labs(title = "Socialization comparison", 
       y = "Socialization score") + 
  theme_minimal()

tokens_plot <- ggplot(df, aes(y = tokens_CHI, x = Diagnosis)) + 
  geom_violin() + 
  labs(title = "Words used comparison", 
       y = "Unique Words Used") + 
  theme_minimal()

score_plot <- ggpubr::ggarrange(non_verbal_plot, verbal_intelligence_plot, Socialization_plot, tokens_plot)

ggsave("score_plot.png", score_plot)


# Demographics compared 
df %>% 
  group_by(Diagnosis) %>% 
  summarise(mean_age = mean(Age, na.rm=T),
            sd_age = sd(Age, na.rm = T),
            pct_male = sum(Gender == "M") / n(), 
            pct_white = sum(str_detect(tolower(Ethnicity), "white")) / n()) %>% 
  mutate(across(where(is.numeric), .fns = ~round(.x, 2)))


```

The sample included mostly white males with ages slightly higher and more varied for the ASD group than the TD group. With regards to non-verbal intelligence, the groups seem evenly matched. For verbal intelligence, the typically developed children scored higher and with less variation according to the boxplot of the data. 


## Let's test hypothesis 1: Children with ASD display a language impairment  (Exercise 2)

### Hypothesis: The child's MLU changes: i) over time, ii) according to diagnosis

Let's start with a simple mixed effects linear model

Remember to plot the data first and then to run a statistical test.
- Which variable(s) should be included as fixed factors?
- Which variable(s) should be included as random factors?

```{r ex2, include = T}
# First we evaluate the hypotheses graphically using a scatter plot
hyp1_plot <- ggplot(df, aes(x = VISIT, y = CHI_MLU, colour = Diagnosis)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(title = "Development over time for ASD vs TD children", 
       x = "Visit number",
       y = "Mean Length of Utterance") + 
  theme_minimal()

ggsave("hyp1_plot.png", hyp1_plot)
```

Graphically, both hypotheses seem to hold: There is a positive slope for both models and the slope for TD is steeper than the ASD slope. However, the plot breaks the assumption of independence. Thus, we need to run a mixed effects model. 

For the model we will use "Diagnosis", "VISIT", and their interaction as as fixed effects and "ID" as random effect. We will not use random slopes because of singular fit :((
```{r ex2 evaluate}
m1 <- lmer(CHI_MLU ~ Diagnosis + VISIT + Diagnosis*VISIT + (1|ID), data=df)
summary(m1)

  ```



How would you evaluate whether the model is a good model?
```{r ex2 evaluate2, include = T}
# Evaluate the models using their R^2 (conditional and marginal)
pacman::p_load("MuMIn")

MuMIn::r.squaredGLMM(m1)
```
We see a marginal R^2 of 0.35 (the variance explained by fixed effects) and a conditional R^2 of 0.77, which is not horrible in social science, but not perfect either... 

Not too good, right? Let's check whether a growth curve model is better.
Remember: a growth curve model assesses whether changes in time can be described by linear, or quadratic, or cubic (or... etc.) components.
First build the different models, then compare them to see which one is better.

```{r ex2 growth curve, include = T}

# Adding squared visit: 
df <- df %>% 
  mutate(SQ_VISIT = VISIT^2,
         CUBE_VISIT = VISIT^3)


quadratic_model <- lmer(CHI_MLU ~ Diagnosis*VISIT + Diagnosis*SQ_VISIT + (1|ID),
                              data=df)
cube_model <- lmer(CHI_MLU ~ Diagnosis*VISIT + Diagnosis*SQ_VISIT + Diagnosis*CUBE_VISIT + (1|ID), data=df)
summary(quadratic_model)
summary(cube_model)
MuMIn::r.squaredGLMM(quadratic_model)
MuMIn::r.squaredGLMM(cube_model)
```

Exciting right? Let's check whether the model is doing an alright job at fitting the data. Plot the actual CHI_MLU data against the predictions of the model fitted(model). 

```{r}
predictions <- fitted(cube_model) %>% 
  as.list %>% 
  as_tibble %>% 
  gather(key = "row_num", value = "pred")

# Plotting the stuff
viz_df <- df %>% 
  mutate(row_num = as.character(row_number())) %>% 
  right_join(predictions) %>% 
  select(row_num, CHI_MLU, pred, Diagnosis)

actual_vs_pred <- ggplot(viz_df, aes(x = CHI_MLU, y = pred)) + 
  geom_point(aes(color = Diagnosis)) + 
  geom_smooth(color="black") + 
  labs(title = "Actual vs Predicted MLU", 
       subtitle = "Cubed model", 
       x = "Actual MLU",
       y = "Modelled MLU") + 
  theme_minimal()

ggsave("act_vs_pred.png", actual_vs_pred)


anova(m1, quadratic_model, cube_model)
```




Now it's time to report our results.
Remember to report:
- the estimates for each predictor (beta estimate, standard error, p-value)
- A plain word description of the results
- A plot of your model's predictions (and some comments on whether the predictions are sensible)

[REPORT THE RESULTS]
Linguistic development of children MLU is affected by the main effect of time (Beta=0.81, df=279.81, t=2.429, p<0.05) and the interactions of normal development and the second order of time (Beta=0.38, df=279.71, t=2.585, p<0.05) and third order of time (Beta=-0.04, df=279.79, t=-2.871, p<0.01). Visual inspection show the model to fit well with the actual data, and residuals to be approximately normal. 

## Let's test hypothesis 2: Parents speak equally to children with ASD and TD  (Exercise 3)

### Hypothesis: Parental MLU changes: i) over time, ii) according to diagnosis

```{r ex3, include = TRUE}
m_parent <- lmer(MOT_MLU ~ VISIT + Diagnosis + Diagnosis*VISIT + (1 + VISIT|ID), 
                 data = df)
summary(m_parent)

```

  Parent MLU is affected by both time (beta = 0.099, df = 57.19, t = 3.738, p < 0.01) and Diagnosis with parents talking more to typically developed children (beta = 0.356, df = 57.91, t = 2.024, p < 0.05) but there's no significant evidence of interaction between time and diagnosis (df = 57.68, t = 1.096, p > 0.05)

### Adding new variables (Exercise 4)

Your task now is to figure out how to best describe the children linguistic trajectory. The dataset contains a bunch of additional demographic, cognitive and clinical variables (e.g.verbal and non-verbal IQ). Try them out and identify the statistical models that best describes your data (that is, the children's MLU). Describe how you selected the best model and send the code to run the model to Victor and Byurakn.



To select the best model, we create a (practically) maximal model including all main effects and two-way interactions. We then used the "step()"-function to iteratively remove unnecessary predictors, creating an impressively explainable model. However, it is important to note that the model is severely overfit (probably), but we will tackle that next week :)). 
```{r ex4, include = TRUE}
library(MASS)

# Rescaling for modelling
df <- df %>% 
  mutate(across(where(is.numeric), scale))

# Creating full model (to trim down later :))
full_model <- lmer(CHI_MLU ~ (VISIT + Diagnosis + Ethnicity + Gender + Age + ADOS + MullenRaw + ExpressiveLangRaw + Socialization + MOT_MLU)^2 + (1|ID), data=df)


best_model <- step(full_model)

# Copy pasted output of step function
besty_model <- lmer(CHI_MLU ~ VISIT + Diagnosis + Ethnicity + Gender + Age + ADOS + 
    MullenRaw + ExpressiveLangRaw + Socialization + MOT_MLU  + VISIT:Diagnosis + VISIT:Age + VISIT:ADOS + VISIT:Socialization + 
    Diagnosis:Ethnicity + Diagnosis:ExpressiveLangRaw + Diagnosis:MOT_MLU + 
    Ethnicity:Gender + Ethnicity:ADOS + Ethnicity:MullenRaw + 
    Ethnicity:ExpressiveLangRaw + Ethnicity:Socialization + Age:ADOS + 
    Age:Socialization + ADOS:ExpressiveLangRaw + MullenRaw:MOT_MLU + (1 | ID), data=df)

# Evaluating model 
summary(besty_model)

# Comparing model
anova(m1, cube_model, besty_model)

# Finding marginal and conditional R^2
MuMIn::r.squaredGLMM(besty_model)

```

In addition to the previously mentioned effects, the MLU of the children is also explained by Verbal IQ (Beta=0.87, df=49.63, t=6.4, p<0.001), the interaction between time and age (Beta=-0.14, df=285.78, t= -4.398, p<0.001), the interaction between time and severity of autism (Beta=-0.68, df=88.24, t=-4.832, p<0.001), the interaction between time and sociability (Beta-0.27, df=80.35, t=-3.027, p<0.01), the interaction between diagnosis and verbal IQ (Beta=0.87, df=47.54, t=-3.494, p<0.01), the interaction between diagnosis and Mother MLU (Beta=-0.23, df=317.30, t=3.190, p<0.01), the interaction between age and autistic severity (Beta=0.57, df=58.66, t=3.114, p<0.01), the interaction between age and sociability (Beta=0.33, df=46.67, t=2.973, p<0.01), the interaction between autistic severity and verbal IQ (Beta=-0.33, df=47.29, t=-2.388, p<0.05), and the interaction between spatial IQ and MLU of the mother (Beta=0.10355, df=319.80, t=2.922, p<0.01).  
Using AIC / nested F-tests as a criterium, we compared models of increasing complexity and found that an elaborate model of the form CHI_MLU ~ VISIT + Diagnosis + Ethnicity + Gender + Age + ADOS +  
    MullenRaw + ExpressiveLangRaw + Socialization + MOT_MLU +  
    VISIT:Diagnosis + VISIT:Age + VISIT:ADOS + VISIT:Socialization +  
    Diagnosis:Ethnicity + Diagnosis:ExpressiveLangRaw + Diagnosis:MOT_MLU +  
    Ethnicity:Gender + Ethnicity:ADOS + Ethnicity:MullenRaw +  
    Ethnicity:ExpressiveLangRaw + Ethnicity:Socialization + Age:ADOS +  
    Age:Socialization + ADOS:ExpressiveLangRaw + MullenRaw:MOT_MLU + (1 | ID), performed significantly better than both baseline and simpler models. The full model had a marginal R^2 of 0.76 and a conditional R^2 of 0.84, thus accurately describing the data.